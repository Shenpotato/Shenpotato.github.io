---
layout: post
title:  "奇异值分解法在降维中的应用"
tags: sad searchengine
author: Shenpotato
catelog: true
---


代码位置：https://github.com/Shenpotato/Singular-Value-Decomposition-Demo

## 一、矩阵需要降维的原因

在search engine中，基于text-document的检索方法下，使用tf，idf，我们能够得到一个document和term的权重矩阵，用于评判哪些term在哪些document中是比较重要的。

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8knv330glj31240r0juc.jpg)

在进行归一化之后，矩阵如下图所示：

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8knvwzugjj313g0qywio.jpg)

但是，我们发现：

随着文章数量的增加，term的数量也会随之增加，并且增长速度很快，给存储和计算带来了很大的问题。

因此，针对这种情况，我们需要对矩阵进行降维。我们引入了奇异值分解法。



## 二、奇异值分解法

### 1、公式表示

奇异值分解法（Singular-Value-Decomposition），本质在于将一个矩阵A分解，表示为：

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8ko15plkij307202at8j.jpg)

其中，U，V都是酉矩阵，满足：

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8ko2iyeebj305c02aq2q.jpg)

我们假设A是一个m x n的矩阵，则U是m x m的矩阵，S是m x n的矩阵，VT是n x n的矩阵。

我们在这里不谈论为什么矩阵可以被分解成这种形式，也不谈论如何分解为这种形式。（这方面内容参考：https://cloud.tencent.com/developer/article/1166583）

我们以如何对矩阵进行降维和其在搜索引擎下的应用为重点。

### 2、矩阵降维

#### （1）在python中的实现

```python
import numpy as np

u, s, v = np.linalg.svd(A)
```

#### （2）S的含义

我们得出的 ‘ s ’ 即为该矩阵的奇异值。我们可以看出，奇异值是通过大小顺序排列的，当我们发现奇异值的前面k项以及占了奇异值总和的大多数时，我们可以用前k项来表示原始矩阵A。

此时，U变为 m x k的矩阵，S为k x k的矩阵，VT变为 k x n的矩阵

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8kodcz6laj31640hktcu.jpg)

如图所示，U变为9 x 2的矩阵，S为2 x 2的矩阵，V变成2 x7的矩阵。



## 三、搜索引擎下的应用

在搜索引擎中，我们得到一个term-document的矩阵，存在term的类似等问题。所以我们需要通过奇异值分解对矩阵进行降维。 

Apply Rank-2 approximation to the decomposed matrices 是指将矩阵降到二维。

原始分解如下：

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8kokgkeq7j308f01pt8i.jpg)

当我们需要对列进行简化时：

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8kolce836j3079019t8i.jpg)

当我们需要对行进行简化时：

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8kokydizoj308w01u3yb.jpg)

在选取的k项的奇异值足够大时，获得的新的矩阵将可代替原矩阵。

代码中降维后的图像实例：

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8konmuxmjj30q60lkt96.jpg)

